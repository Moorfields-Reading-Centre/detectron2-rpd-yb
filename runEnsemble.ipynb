{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import detectron2\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "from plain_train_net import grab_dataset\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.engine import launch\n",
    "\n",
    "\n",
    "reprocess_results=True\n",
    "# dataset_name = \"reserves_fold1\"\n",
    "dataset_name = \"Fold 1\"\n",
    "dpi=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "from detectron2.config import get_cfg\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('configs/working.yaml')\n",
    "#really low iou for nms in order to separate out lesions\n",
    "# cfg.merge_from_list([\"MODEL.WEIGHTS\", \"output_valid_fold1/model_final.pth\",\n",
    "#                      \"OUTPUT_DIR\", \"output_valid_\"+ dataset_name + \"/results\"])\n",
    "#print(cfg.dump())  # print formatted configs\n",
    "print(cfg.MODEL.ROI_HEADS.dump())\n",
    "print(cfg.MODEL.WEIGHTS)\n",
    "print(cfg.OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [dataset_name]:\n",
    "    try:\n",
    "        DatasetCatalog.register(name, grab_dataset(name))\n",
    "    except:\n",
    "        print('Already registered.')\n",
    "        #do nothing\n",
    "    MetadataCatalog.get(name).thing_classes = [\"rpd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%script false --no-raise-error\n",
    "#os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "#from torch.nn.parallel import DistributedDataParallel\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "#from plain_train_net import EvaluateClass\n",
    "from detectron2.evaluation import inference_on_dataset, COCOEvaluator\n",
    "\n",
    "def predict_func(cfg,dataset_name):\n",
    "    model = build_model(cfg)  # returns a torch.nn.Module\n",
    "    \n",
    "    # distributed = comm.get_world_size() > 1\n",
    "    # if distributed:\n",
    "    #     model = DistributedDataParallel(\n",
    "    #         model, device_ids=[comm.get_local_rank()], broadcast_buffers=False\n",
    "    #     )\n",
    "    \n",
    "    myloader = build_detection_test_loader(cfg,dataset_name) \n",
    "    myeval = COCOEvaluator(dataset_name,tasks={'bbox','segm'},output_dir =\"output_\"+ dataset_name) #produces _coco_format.json when initialized\n",
    "\n",
    "\n",
    "    for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "        #build model\n",
    "        model_weights_path = \"/data/amd-data/cera-rpd/detectron2-rpd/output_valid_\"+ mdl +\"/model_final.pth\"\n",
    "        DetectionCheckpointer(model).load(model_weights_path);  # load a file, usually from cfg.MODEL.WEIGHTS\n",
    "        model.eval(); #set model in evaluation mode\n",
    "        myeval.reset()\n",
    "        output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "        myeval._output_dir = output_dir\n",
    "        print(\"running inference on \", mdl)\n",
    "        results_i = inference_on_dataset(model, myloader, myeval) #produces coco_instance_results.json when myeval.evaluate is called\n",
    "    \n",
    "    return  \n",
    "predict_func(cfg,dataset_name)\n",
    "print(\"done predict_func\")\n",
    "# launch(\n",
    "#     predict_func,\n",
    "#     6, # of gpus\n",
    "#     num_machines=1,\n",
    "#     machine_rank=0,\n",
    "#     dist_url=\"auto\",\n",
    "#     args=(cfg,dataset_name,), #args to predict_func\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Fold 1/fold1/coco_instances_results.json into memory. 239 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Fold 1/fold2/coco_instances_results.json into memory. 243 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Fold 1/fold3/coco_instances_results.json into memory. 247 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Fold 1/fold4/coco_instances_results.json into memory. 191 instance detected.\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Successfully loaded output_Fold 1/fold5/coco_instances_results.json into memory. 240 instance detected.\n",
      "\n",
      "Working with 5 models, 1 categories, and 64 images.\n",
      "Computing mean score non-max suppression ensembling for 64 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 61.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 resulting instances from NMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "from Ensembler import Ensembler\n",
    "ens = Ensembler('output_'+dataset_name,dataset_name,[\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"],.2)\n",
    "ens.mean_score_nms()\n",
    "ens.save_coco_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from plain_train_net import EvaluateClass,CreatePlotsRPD\n",
    "import json\n",
    "#evaluate ensemble\n",
    "myeval = EvaluateClass(\n",
    "    dataset_name, \"output_\"+ dataset_name,iou_thresh = .2,prob_thresh=0.5,evalsuper=False)\n",
    "myeval.evaluate()\n",
    "%precision 3\n",
    "print(myeval.summarize_scalars())\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json'),\"w\") as outfile:\n",
    "    json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n",
    "num_images = myeval.num_images\n",
    "myeval.plot_PRcurve()\n",
    "plt.tight_layout()\n",
    "myeval.plot_recall_vs_prob()\n",
    "plt.tight_layout()\n",
    "\n",
    "RPDplt = CreatePlotsRPD.initfromcoco(myeval.mycoco,myeval.prob_thresh)\n",
    "RPDplt.gt_dt_FP_FN_count();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate individual models\n",
    "import json\n",
    "myeval.evalsuper=False\n",
    "for mdl in (\"fold1\", \"fold2\", \"fold3\", \"fold4\",\"fold5\"):\n",
    "    myeval.reset()\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    myeval._output_dir = output_dir\n",
    "    myeval.evaluate()\n",
    "    print(myeval.summarize_scalars())\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json'),\"w\") as outfile:\n",
    "        json.dump(obj=myeval.summarize_scalars(),fp=outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from table_styles import styles\n",
    "mydicts=[]\n",
    "for mdl in ['fold1','fold2','fold3','fold4','fold5']:\n",
    "    output_dir = \"output_\"+ dataset_name + \"/\"+mdl\n",
    "    with open(os.path.join(output_dir,'scalar_dict.json')) as f:\n",
    "        mydicts.append(json.load(f))\n",
    "with open(os.path.join(\"output_\"+ dataset_name,'scalar_dict.json')) as f:\n",
    "    mydicts.append(json.load(f))\n",
    "dfr = pd.DataFrame(mydicts)\n",
    "dfr = dfr.assign(fp = np.int32(dfr.fpr*num_images))\n",
    "dfr = dfr.assign(f1 = 2*(dfr.precision*dfr.recall)/(dfr.precision + dfr.recall))\n",
    "dfr = dfr.assign(model = ['1','2','3','4','5','ensemble'])\n",
    "# dfr = dfr[['model','fpr','fp','probability','dataset']]\n",
    "dfr = dfr[['model','dataset','precision','recall','f1','fpr','fp','iou','probability']]\n",
    "pd.set_option('display.precision',3)\n",
    "dfr.style.set_table_styles(styles).set_table_attributes('style=\"font-size: 17px\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from plain_train_net import OutputVis\n",
    "\n",
    "dataset_name = 'Fold 1'\n",
    "pred_file = \"output_\"+ dataset_name + \"/coco_instances_results.json\"\n",
    "out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+dataset_name+'_nonrpd.pdf')\n",
    "\n",
    "# mdl = 'fold1'\n",
    "# pred_file = os.path.join(\"output_\"+ dataset_name,mdl,\"coco_instances_results.json\")\n",
    "# out_file = os.path.join(\"output_\"+ dataset_name,'mean_score_nms_'+mdl+'.pdf')\n",
    "\n",
    "# vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=False)\n",
    "# ImgIds = RPDplt.dfimg.index[RPDplt.dfimg.dt_instances>0] #np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:50].values\n",
    "# vis.output_to_pdf(ImgIds,out_file)\n",
    "\n",
    "df = RPDplt.dfimg\n",
    "vis = OutputVis(dataset_name,prob_thresh = 0.5,pred_mode='file',pred_file=pred_file,has_annotations=False)\n",
    "ImgIds = RPDplt.dfimg[RPDplt.dfimg.dt_instances==0].sample(50).index.values\n",
    "#ImgIds = np.abs(df.gt_xpxs-df.dt_xpxs).sort_values(ascending=False).index[0:10].values\n",
    "vis.output_to_pdf(ImgIds,out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_styles import styles\n",
    "dfpts = RPDplt.dfpts.sort_values(by=['dt_instances'],ascending=False)\n",
    "html_str = dfpts.style.format('{:.0f}').set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfpts_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfimg = RPDplt.dfimg.sort_index()\n",
    "html_str = dfimg.style.set_table_styles(styles).render()\n",
    "html_file = open(os.path.join('output_'+ dataset_name + '/dfimg_'+dataset_name+'.html'),'w')\n",
    "html_file.write(html_str)\n",
    "html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpts.sum()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0122a9a100fde86447053a2d82169efd56332aef873a4abfb4540bf3c983ad4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('detectron': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
